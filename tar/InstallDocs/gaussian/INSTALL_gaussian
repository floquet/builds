For topaz, http://www.gaussian.com/g_prod/g09_plat.pdf
says building from source needs PGI F77 compiler and Gnu compiler for C,
and Atlas.  Except for Itanium.  For Altix ICE (not shared memory
outside of each node, i.e. not UV) I wonder if the Intel compiler
suite can be used for both Fortran and C?  Also, can MKL be used
instead of Atlas?  My build notes for diamond mentions the MKL library.

Users manual available online
http://www.gaussian.com/g_tech/g_ur/g09help.htm
http://www.gaussian.com/g_tech/g_ur/m_running.htm
/home/scheinin/Desktop/Gaussian/g09w_ref.pdf

/bin/tcsh
setenv g09root /usr/local/applic/gaussian/g09.B01

# Inside subdirectory "tar/" there is a gzipped tar file
# that has the prebuilt version of Gaussian.

cd $g09root

# jade
tar xvzf /work/scheinin/Gaussian/tar/OPT-S93N.tgz

# diamond
tar xvzf /work/scheinin/Gaussian/tar/E64-930N.tgz

chgrp -R gaussian g09
cd g09
 ./bsd/install

Just for the record, both the OPT-S93N and E64-930N distributions
only have linda8.2/opteron-linux .

The instruction page "Building G09 with Linda" says to
install from source then install from the Linda CD
then run
mg linda
but there is an error "No rule to make target `bsd/g09.make'."
In fact, the bsd/install mentioned linda and so it is likely
that the instruction page is for building from source whereas
the CD used already as Linda built-in.

cd /usr/local/applic/gaussian
chgrp -R gaussian g09.B01
chmod -R 750 g09.B01
(A bit much because now all files are executable.)

create appwrap link
$g09root/g09/g09 becomes $g09root/g09/g09.orig
and create
g09 -> /usr/local/usp/appwrap/appwrap.pl

create module and update default version

# Users should set
# csh, tcsh
setenv g09root /usr/local/applic/gaussian/g09.B01
setenv $GAUSS_SCRDIR $WORKDIR/tmp
source $g09root/g09/bsd/g09.login

# ksh, bash
export g09root=/usr/local/applic/gaussian/g09.B01
export GAUSS_SCRDIR=$WORKDIR/tmp
. $g09root/g09/bsd/g09.profile

export GAUSS_LFLAGS='-opt "Tsnet.Node.lindarsharg: ssh"'

The environment variable GAUSS_SCRDIR can be different from that shown
in the example.  It should be a scratch directory in the user's
WORKDIR and should not be the local /tmp directory of the node.

It may be necessary to set GAUSS_SCRDIR in .cshrc or .profile
because the environment variables may not be passed to all nodes.

Gaussian 09 gets configuration information from three primary sources

    * The Gaussian input file via %Link0 commands.
    * The Default.Route file.
    * The environment variable GAUSS_LFLAGS. 

Details about %Link0 commands and the Default.Route file
can also be found in the Gaussian 09 Users Reference manual.
Entries specific to Gaussian 09/Linda are described below.

# Need to create a unique set of nodes.

%LindaWorkers=node1,node2

# jade-ES
%NProcShared=16
# diamond
%NProcShared=8

% setenv GAUSS_LFLAGS '... -opt "Tsnet.Node.lindarsharg: ssh"
"..." means other options.
or
in $HOME directory, file .tsnet.config should contain the line
Tsnet.Node.lindarsharg: ssh

Add to GAUSS_LFLAGS "-v" or "-vv" for verbose or very verbose.

# After source of the configuration file,  run using
g09 input &

Should see processes with name lxxx.exel 

For jade, just use jade-ES1 and jade-ES3
Need to have .ssh/known_hosts writable and
login once in both directions to add the machines
so that ssh during parallel run does not require a response.

ssh jade-es1


ssh jade-es3

For test in /work/scheinin/gausstest/tests
mkdir amd64

created a fort.7 where the job was run even though
put into submit.csh

setenv g09root /usr/local/applic/gaussian/g09.B01
setenv GAUSS_SCRDIR "${WORKDIR}/tmp"
source $g09root/g09/bsd/g09.login

HF, CIS=Direct, and DFT calculations on molecules are Linda parallel, including energies, optimizations and frequencies. TDDFT energies and gradients and MP2 energies and gradients are also Linda parallel. Portions of MP2 frequency and CCSD calculations are Linda parallel, but others are only SMP-parallel, so they see some speedup from using a few nodes but no further improvement from larger numbers of nodes.

 -------------
reminding me what I did on jade
%NProcShared=16
./com/test026.com
%NProcShared=16
./com/test115.com
%NProcShared=16
./com/test247.com

Need to see letter on where to put that when there is more
than one link.

Set in environment, on jade the following does not seem to
be in any file, must have been set by hand.
export GAUSS_LFLAGS='-opt "Tsnet.Node.lindarsharg: ssh"'
Log file shows
 %LindaWorkers=jade-es3
 SetLPE:  input flags="-opt "Tsnet.Node.lindarsharg: ssh" "
 SetLPE:    new flags="-opt "Tsnet.Node.lindarsharg: ssh"  -nodelist 'jade-es3.erdc.hpc.mil'"

%LindaWorkers=jade-es3
in *.com file

How does g09 know where to look for the configuration file?  The first
file after g09 ?

 -------------

From help@gaussian


   Dr. Scheinine,

      Thank you for giving us a chance to comment.

      First, the use of parallelism does not reduce the CPU time required for a calculation but rather the elapsed time.  Test247 is not a good measure of this since it is very short and spends almost all of its time in process initialization and termination.

      Second, since it is a multistep job you need to incorporate the lines

%nprocs=16
%LindaWorkers=jade-es3

after each --Link1-- line to have the later steps run in parallel as well.

      So take a test like g09/tests/com/test397.com which will run much longer and is only a single job step.  Modify this to try different numbers of processors, with and without Linda.  Then use

time g09 test397.com

so that you get a report on both elapsed time and CPU time to see the speedup.



On Fri, Sep 03, 2010 at 05:39:06PM -0400, Scheinine, Alan ERDC-ITL-MS Contractor wrote:
> I have installed Gaussian with Linda on a Cray XT4 at ERDC, one of the 
> DoD HPC Modernization Program machines named "jade".  Our maintenance P.O.
> number
> is T51495/O1086.
> 
> The tests I tried, from the "tests" subdirectory, run fine as serial 
> jobs but I am unable to obtain SMP performance.  (I will be testing 
> Linda after first testing the SMP feature.)  Take for example test247, 
> which is part of "run-dft" test.  I added
> 
> %LindaWorkers=jade-es3
> %NProcShared=16
> 
> as the first two lines of the file test247.com.  The node has 16 
> cores.  To be certain of the environment, in the submit.csh script I 
> added
> 
> setenv g09root /usr/local/applic/gaussian/g09.B01
> setenv $GAUSS_SCRDIR $WORKDIR/tmp
> source $g09root/g09/bsd/g09.login
> 
> The log file has the lines
> 
>  ******************************************
>  Gaussian 09:  AM64L-G09RevB.01 12-Aug-2010
>                  3-Sep-2010
>  ******************************************
>  %LindaWorkers=jade-es3
>  SetLPE:  input flags="-opt "Tsnet.Node.lindarsharg: ssh" "
>  SetLPE:    new flags="-opt "Tsnet.Node.lindarsharg: ssh"  -nodelist
> 'jade-es3.e
> rdc.hpc.mil'"
>  Will use up to    1 processors via Linda.
>  %NProcShared=16
>  Will use up to   16 processors via shared memory.
> 
> The job is being submitted on and run on node jade-es3.erdc.hpc.mil.
> I also tried eliminating the line "%LindaWorkers=jade-es3" since I am 
> only testing SMP, but doing so made no difference.
> 
> The "top" command shows only one process with or without 
> "%NProcShared=16" , and the execution time is always the same, around 
> 22 seconds.  The instructions 
> "http://www.gaussian.com/g_tech/g_ur/m_linda.htm" describe the lines 
> to be added but do not say where the lines should be added.  The log file indicates that I should expect SMP performance.  The "tests"
> subdirectory of the AMD64/Linux w/LINDA CD-ROM do not have any files 
> with the string "Shared" so evidently there are no tests specifically 
> written for SMP usage that I could use as an example.
> 
> Alan Scheinine, HPC Service Helpdesk, ERDC, Vicksburg
>  

--
Douglas J. Fox
Technical Support
Gaussian, Inc.
help@gaussian.com

 ==============


If you add  "Tsnet.Node.lindarsharg: ssh" to the GAUSS_LFLAGS.


> 
> When you run Gaussian with Linda on the SGI does linda use ssh 
> interchangeably with rsh?
> 

 ------------------------------------
mica, below

# In $HOME , because there is no $WORKDIR ,
# because the tarball files are not all in an overall
# common directory make directory Gaussian.
mkdir Gaussian
mv Gaussian09.B01-amd64-with-linda.tgz Gaussian
cd Gaussian
tar xzf Gaussian09.B01-amd64-with-linda.tgz

# Installation of Gaussian seems be be based on tcsh.
/bin/tcsh
setenv g09root /usr/local/applic/gaussian/g09.B01
mkdir $g09root

# Inside subdirectory "tar/" there is a gzipped tar file
# that has the prebuilt version of Gaussian.

cd $g09root

tar xvzf /u/scheinin/Gaussian/tar/OPT-S93N.tgz

# Need to create group gaussian, mica does not now have that group.
chgrp -R gaussian g09
cd g09
 ./bsd/install

See
http://www.gaussian.com/g_tech/g_ur/g09help.htm
http://www.gaussian.com/g_tech/g_ur/m_running.htm

Need to understand ccm_start
S-2496-32 Workload Management and Application Placemet
for the Cray Linux Environment, Chapter 6 is CCM.

queue "-q ccm"
qsub -V -l -q ccm_queue -lmppwidth=xxx lmppnppn=x
ccmrun -n1 app1  (-n1???)
ccmlogin nidXXXX provides an interactive window to the job

load ccm module
commands are ccmrun and ccmlogin
ccmrun section says there are no option (w.r.t. what is -l?)
ccmlogin allows interactive login to head ccm node and ssh to other nodes

qsub -I -l mppwidth=32 -q ccm_queue

#PBS -l mppwidth=32
#PBS -q ccm_queue
#PBS -j eo
#PBS -S /bin/bash
cd $PBS_O_WORKDIR
export PATH=${PATH}:/mnt/luster_server/ccmuser/isv_app/Commands
# above is for the application
export TMPDIR= ..etc...
ccmrun isv_app  application options

Example
module load ccm
qsub -V -q ccm_queue -I -lmppwidth=2 -l mppnodes=471
export LD_LIBRARY_PATH  etc.
cmmrun -n2 executable
This is weird because of the -n2

aprun    qsub
-n 4     -l mppwidth=4    number of PEs
-d 2     -l mppdepth-2    number of CPUs hosting OpenMP threads
-N 1     -l mppnppn=1     Number of PEs per node
-L 5,6,7 -l mppnodes=\"5,6,7\"  candidate node list
-m 1000   -l mppmem=1000   memory per PE

#PBS -l ncpus=4

# Users should set
# csh, tcsh
setenv g09root /usr/local/applic/gaussian/g09.B01
setenv $GAUSS_SCRDIR $WORKDIR/tmp
source $g09root/g09/bsd/g09.login

# ksh, bash
export g09root=/usr/local/applic/gaussian/g09.B01
export GAUSS_SCRDIR=$WORKDIR/tmp
. $g09root/g09/bsd/g09.profile



export GAUSS_LFLAGS='-opt "Tsnet.Node.lindarsharg: ssh"'


To be done:
1) Change group to gaussian for all files and directories in
   /usr/local/applic/gaussian/g09.B01
   (Group "gaussian" not now in /etc/group.)
2) Install /usr/local/usp/appwrap/appwrap.pl
   move g09 to g09.orig
   point g09 to the appwrap.pl
3) create module

#!/bin/sh
machinefile="/tmp/pbs_mpimach$$"
cat -n ${PBS_NODEFILE} | \
	sort -k2 | uniq -f1 -c | \
	awk '{if ($1 == 1) print $2, $3; else print $2, $3 ":" $1}' | \
	sort -n | awk '{print $2}' > $machinefile

   cat -n $nodelistfile | \
     sort -k2 | uniq -f1 -c | \
     awk '{if ($1 == 1) print $2, $3; else print $2, $3 ":" $1}' | \
     sort -n | awk '{print $2}'

I do not understand why line numbers need to be added in the first cat,
but certainly two sorts are required, otherwise nodes found in two
different places might result in
4 node1
4 node2
4 node1

instead of
8 node1
4 node2


cat
       -n   number output lines
results in leading space
  
sort
       -k, --key=POS1[,POS2]
              start a key at POS1, end it at POS2 (origin 1)
this sort seems superfluous

uniq
       -c, --count
              prefix lines by the number of occurrences
       -f, --skip-fields=N
              avoid comparing the first N fields

w.r.t. awk, what would the third field be?

On diamond:


 qsub -A erdcssta -q debug -l select=2:ncpus=8:mpiprocs=8,place=scatter:excl,walltime=0:59:00 -I


cd /work/scheinin/gausstest/tests/work


mica, above
 ------------------------------------
submit script
there is no PBS example, but Gaussian provides and NQS example
But it seems to be a single-node version.
#!/bin/csh -f
#
# Submit a Gaussian 09 job to an nqs batch queue.
#
# $1      -- name of queue.
# $2      -- name of input file.
# $3, etc -- extra flags for qsub.  The first pair can be -scrdir xxx to
#            use scratch directory xxx.  Second can be either -g88 or
#            -g86 to request executables out of /g88 or /g86 or
#            -exedir xxx to use executables out of xxx.
#
# Generate script, explicitly requesting the csh.
#
cat <<END >$2.job
#!/bin/csh
cd \$QSUB_WORKDIR
source $g09root/g09/bsd/gau-unlimit
g09 <$2.com >&$2.log
END
@ swstart = 3
#
# Insert any extra commands.
#
if ($#argv >= $swstart) then
  if ("$argv[$swstart]" == "-scrdir") then
    @ swstart1 = $swstart + 1
    /bin/ed <<END $2.job
    /g09/p
    i
    setenv GAUSS_SCRDIR $argv[$swstart1]
.
    w
    q
END
    @ swstart = $swstart + 2 
    endif
  endif
if ($#argv >= $swstart) then
  if ("$argv[$swstart]" == "-g86") then
    /bin/ed <<END $2.job
    s?g09?g09 -exedir /m10/2/frisch/g86?p
    i
    setenv GAUSS_EXEDIR /m10/2/frisch/g86
.
    w
    q
END
    @ swstart = $swstart + 1
    endif
  endif
if ($#argv >= $swstart) then
  if ("$argv[$swstart]" == "-g88") then
    /bin/ed <<END $2.job
    s?g09?g09 -exedir /m10/2/frisch/g88?p
    i
    setenv GAUSS_EXEDIR /m10/2/frisch/g88
.
    w
    q
END
    @ swstart = $swstart + 1
    endif
  endif
if ($#argv >= $swstart) then
  if ("$argv[$swstart]" == "-exedir") then
    @ swstart1 = $swstart + 1
    /bin/ed <<END $2.job
    s?g09?g09 -exedir $argv[$swstart1]?p
    i
    setenv GAUSS_EXEDIR $argv[$swstart1]
.
    w
    q
END
    @ swstart = $swstart + 2 
    endif
  endif
#
# Now submit it.
#
qsub -q $1 -nr -eo -r $2 -x -o $2.batch-log $argv[$swstart-] $2.job
rm $2.job

 ------------------------------------
-l mppwidth=32 rather than ncpus
 qsub -A erdcstaa -q ccm_queue -l ncpus=32 -l walltime=00:10:00 -I

To get to a node on which I can do other ssh
ccmlogin AFTER doing qsub
but on 

Correct way to set permissions

 find . -perm -u=x

find . -perm -u=x -exec chmod go+x {} \;

ssh should be

# /usr/local/krb5/bin/ssh -F /etc/ssh/ssh_config
 /opt/site/bin/ssh -F /etc/ssh/ssh_config

 ----

Here is the script I'm using to run Gaussian without Linda

#!/bin/csh
#PBS -l mppwidth=1
#PBS -l mppnppn=1
#PBS -j oe
#PBS -o gauss-test.native.log
#PBS -N gauss-test
## #PBS -q ccm_queue

cd $PBS_O_WORKDIR
## module load ccm
mkdir -p scratch

rm -f Default.Route
rm -f node_file
echo "-P- 2" > Default.Route

setenv g09root /usr/local/applic/gaussian/g09.B01
setenv GAUSS_EXEDIR  ${g09root}/g09
setenv GAUSS_EXEDIR ${g09root}/g09/linda-exe:$GAUSS_EXEDIR
setenv GAUSS_SCRDIR /work/aminga/isvdata/Gaussian/scratch
setenv TMPDIR /work/aminga/isvdata/Gaussian/scratch
source ${g09root}/g09/bsd/g09.login
setenv GAUSS_LFLAGS '-vv'

aprun ${g09root}/g09/g09 < gauss-test.com > gauss-test_native.out

And the resulting output

aminga@mica01:/work/aminga/isvdata/Gaussian> more gauss-test_native.out  Entering Gaussian System, Link 0=/usr/local/applic/gaussian/g09.B01/g09/g09
 Initial command:
 /usr/local/applic/gaussian/g09.B01/g09/l1.exe /work/aminga/isvdata/Gaussian/scratc
h/Gau-10042.inp -scrdir=/work/aminga/isvdata/Gaussian/scratch/
 Default is to use a total of   2 processors:
                                2 via shared-memory
                                1 via Linda
 Entering Link 1 = /usr/local/applic/gaussian/g09.B01/g09/l1.exe PID=     10043.

 Copyright (c) 1988,1990,1992,1993,1995,1998,2003,2009,2010,
            Gaussian, Inc.  All Rights Reserved.

 This is part of the Gaussian(R) 09 program.  It is based on  the Gaussian(R) 03 system (copyright 2003, Gaussian, Inc.),  the Gaussian(R) 98 system (copyright 1998, Gaussian, Inc.),  the Gaussian(R) 94 system (copyright 1995, Gaussian, Inc.),  the Gaussian 92(TM) system (copyright 1992, Gaussian, Inc.),  the Gaussian 90(TM) system (copyright 1990, Gaussian, Inc.),  the Gaussian 88(TM) system (copyright 1988, Gaussian, Inc.),  the Gaussian 86(TM) system (copyright 1986, Carnegie Mellon  University), and the Gaussian 82(TM) system (copyright 1983,  Carnegie Mellon University). Gaussian is a federally registered  trademark of Gaussian, Inc.

 This software contains proprietary and confidential information,  including trade secrets, belonging to Gaussian, Inc.

 This software is provided under written license and may be  used, copied, transmitted, or stored only in accord with that  written license.

 The following legend is applicable only to US Government  contracts under FAR:

                    RESTRICTED RIGHTS LEGEND

 Use, reproduction and disclosure by the US Government is  subject to restrictions as set forth in subparagraphs (a)  and (c) of the Commercial Computer Software - Restricted  Rights clause in FAR 52.227-19.

 Gaussian, Inc.
 340 Quinnipiac St., Bldg. 40, Wallingford CT 06492


 ---------------------------------------------------------------
 Warning -- This program may not be used in any manner that  competes with the business of Gaussian, Inc. or will provide  assistance to any competitor of Gaussian, Inc.  The licensee  of this program is prohibited from giving any competitor of  Gaussian, Inc. access to this program.  By using this program,  the user acknowledges that Gaussian, Inc. is engaged in the  business of creating and licensing software in the field of  computational chemistry and represents and warrants to the  licensee that it is not a competitor of Gaussian, Inc. and that  it will not use this program in any manner prohibited above.
 ---------------------------------------------------------------


 Cite this work as:
 Gaussian 09, Revision B.01,
 M. J. Frisch, G. W. Trucks, H. B. Schlegel, G. E. Scuseria,  M. A. Robb, J. R. Cheeseman, G. Scalmani, V. Barone, B. Mennucci,  G. A. Petersson, H. Nakatsuji, M. Caricato, X. Li, H. P. Hratchian,  A. F. Izmaylov, J. Bloino, G. Zheng, J. L. Sonnenberg, M. Hada,  M. Ehara, K. Toyota, R. Fukuda, J. Hasegawa, M. Ishida, T. Nakajima,  Y. Honda, O. Kitao, H. Nakai, T. Vreven, J. A. Montgomery, Jr.,  J. E. Peralta, F. Ogliaro, M. Bearpark, J. J. Heyd, E. Brothers,  K. N. Kudin, V. N. Staroverov, T. Keith, R. Kobayashi, J. Normand,  K. Raghavachari, A. Rendell, J. C. Burant, S. S. Iyengar, J. Tomasi,  M. Cossi, N. Rega, J. M. Millam, M. Klene, J. E. Knox, J. B. Cross,  V. Bakken, C. Adamo, J. Jaramillo, R. Gomperts, R. E. Stratmann,  O. Yazyev, A. J. Austin, R. Cammi, C. Pomelli, J. W. Ochterski,  R. L. Martin, K. Morokuma, V. G. Zakrzewski, G. A. Voth,  P. Salvador, J. J. Dannenberg, S. Dapprich, A. D. Daniels,  O. Farkas, J. B. Foresman, J. V. Ortiz, J. Cioslowski,  and D. J. Fox, Gaussian, Inc., Wallingford CT, 2010.

 ******************************************
 Gaussian 09:  AM64L-G09RevB.01 12-Aug-2010
                24-Sep-2010
 ******************************************
 -------------------------------------
 # p m062x/aug-cc-pvtz opt(maxcycle=2)
 -------------------------------------
 1/6=2,14=-1,18=20,19=15,26=3,38=1/1,3;
 2/9=110,12=2,17=6,18=5,40=1/2;
 3/5=16,6=1,7=10,11=2,16=1,25=1,30=1,71=1,74=-55/1,2,3;
 4//1;
 5/5=2,38=5/2;
 6/7=2,8=2,9=2,10=2,28=1/1;
 7//1,2,3,16;
 1/6=2,14=-1,18=20,19=15/3(2);
 2/9=110/2;
 99//99;
 2/9=110/2;
 3/5=16,6=1,7=10,11=2,16=1,25=1,30=1,71=1,74=-55/1,2,3;
 4/5=5,16=3/1;
 5/5=2,38=5/2;
 7//1,2,3,16;
 1/6=2,14=-1,18=20,19=15/3(-5);
 2/9=110/2;
 6/7=2,8=2,9=2,10=2,19=2,28=1/1;
 99/9=1/99;
No executable for file l101.exe.

Search path GAUSS_EXEDIR is "/usr/local/applic/gaussian/g09.B01/g09/bsd:/usr/local/
applic/gaussian/g09.B01/g09/local:/usr/local/applic/gaussian/g09.B01/g09/extras:/us
r/local/applic/gaussian/g09.B01/g09"

Application 1148 exit codes: 1
Application 1148 resources: utime ~0s, stime ~0s

> -----Original Message-----
> From: Scheinine, Alan ERDC-ITL-MS Contractor 
> [mailto:Alan.Scheinine@usace.army.mil]
> Sent: Saturday, September 25, 2010 3:14 PM
> To: Alan Minga
> Subject: RE: Gaussian
> 
> Alan,
>  You wrote, "Not sure if this helps ..."  I need more help.  What test 
> case did you run?  The test case I ran worked in the interactive mode.  
> Another
> question: show us your batch script.  How did you setup the environment?
> Are
> the environment variables get passed to the compute nodes?  One thing 
> I notice, there is the line
> 
> ccmrun /usr/local/applic/gaussian/g09.B01/g09/g09
> 
> with no file describing the run parameters after the executable.
> 
> Regards,
> Alan Scheinine, HPC Service Helpdesk, ERDC, Vicksburg
> 
> 
> -----Original Message-----
> From: Alan Minga [mailto:aminga@cray.com]
> Sent: Friday, September 24, 2010 9:19 PM
> To: Scheinine, Alan ERDC-ITL-MS Contractor
> Cc: Alter, Robert W ERDC-ITL-MS
> Subject: RE: Gaussian
> 
> Not sure if this helps but running on a single node without linda 
> generates a core dump in l101.exe
> 
> set LINDA_LAUNCHVERBOSE=1
> ccmrun /usr/local/applic/gaussian/g09.B01/g09/g09
> Error: segmentation violation
>    rax 0000000000000000, rbx ffffffffffffffff, rcx ffffffffffffffff
>    rdx 00000000000023f0, rsp 00007ffffffd6298, rbp 00007ffffffd6870
>    rsi 000000000000000b, rdi 00000000000023f0, r8  00007ffffffd6288
>    r9  00002aaaab4909c0, r10 0000000000000000, r11 0000000000000202
>    r12 0000000000000000, r13 0000000000000000, r14 00007ffffffd68b8
>    r15 0000000000000006
>   --- traceback not available
> 
> > -----Original Message-----
> > From: Scheinine, Alan ERDC-ITL-MS Contractor 
> > [mailto:Alan.Scheinine@usace.army.mil]
> > Sent: Friday, September 24, 2010 5:50 PM
> > To: Alan Minga
> > Subject: RE: Gaussian
> >
> > Alan,
> >    I was a slow in getting back to you because I checked group 
> > execute permissions also on various subdirectories.  I think it is right now.
> >
> > Alan Scheinine, HPC Service Helpdesk, ERDC, Vicksburg
> >
> >
> > -----Original Message-----
> > From: Alan Minga [mailto:aminga@cray.com]
> > Sent: Friday, September 24, 2010 5:20 PM
> > To: Scheinine, Alan ERDC-ITL-MS Contractor; Alter, Robert W 
> > ERDC-ITL-MS
> > Subject: RE: Matlab
> >
> > You have to use the IP on the compute nodes
> >
> > > -----Original Message-----
> > > From: Scheinine, Alan ERDC-ITL-MS Contractor 
> > > [mailto:Alan.Scheinine@usace.army.mil]
> > > Sent: Friday, September 24, 2010 5:18 PM
> > > To: Alter, Robert W ERDC-ITL-MS; Alan Minga
> > > Subject: RE: Matlab
> > >
> > > Bob,
> > >
> > > The installation procedure from MatLab requires a license file, a 
> > > file!  The installer does not have an option for a network license.
> > > The "help" says to contact your system administrator if you have a 
> > > network license but the installer does not provide the option of
> > specifying
> > a remote host.
> > >
> > > By the way, the compute nodes don't have machine name resolution, 
> > > it seems to me.
> > > rls1.csi.hpc.mil is 140.32.131.130  (and so on for 2 & 3)
> > > On a compute node  telent 140.32.131.130 1725   shows that the hole is
> > open.
> > >
> > > Alan Scheinine, HPC Service Helpdesk, ERDC, Vicksburg

=========================
 Linda on Diamond.

Copied all of
/usr/local/applic/gaussian/g09.B01/g09/tests
to
/work/scheinin/gaussian/original/

Doing experiments in
/work/scheinin/gaussian/work

#Interactive experiment using
 qsub -A  ERDCS97290STA -q standard \
 -l select=4:ncpus=8:mpiprocs=8,place=scatter:excl,walltime=1:00:00 -I

cd $PBS_O_WORKDIR

export g09root=/usr/local/applic/gaussian/g09.B01
export GAUSS_SCRDIR=/u/scheinin/tmp
source $g09root/g09/bsd/g09.profile

# Define remote shell command
# export GAUSS_LFLAGS="$GAUSS_LFLAGS -opt \"Tsnet.Node.lindarsharg: ssh\""
# There is no other text in GAUSS_LFLAGS so no need to use $GAUSS_LFLAGS.
export GAUSS_LFLAGS=" -opt \"Tsnet.Node.lindarsharg: ssh\""

# Note that /usr/bin/ssh would be a more precise file pathname but
# Gaussian parsing of needs the simpler executable name or
# linda_rsh in Gaussian need to be modified.
# /usr/local/applic/gaussian/g09.B01/g09/linda8.2/opteron-linux/bin/linda_rsh

# Generate a test command file using

lindaworkers='%LindaWorkers'
workerstmp=`cat -n ${PBS_NODEFILE} | \
  sort -k2 | uniq -f1 -c | \
  awk '{print $2, $3}' | \
  sort -n | awk '{print $2}'`

for i in $workerstmp ; do
   lindaworkers=${lindaworkers},$i
done
lindaworkers=`echo ${lindaworkers} | sed -e "s/LindaWorkers,/LindaWorkers=/"`

cp /work/scheinin/gaussian/original/com/test397.com test.user

echo " "  > test.preamble
echo "$lindaworkers" >> test.preamble
echo '%NProcShared=8' >> test.preamble

cat test.preamble test.user > test.com

look at $lindaworkers in order to know which nodes I can log-into in
order to watch the CPU usage.

# Can run using
# tee does not seem to work on compute node
# time g09 test.com 2>&1 | tee test.log

TBEGIN=`echo "print time();" | perl` ; \
time g09 test.com > test.log 2>&1 ; \
TEND=`echo "print time();" | perl` ; \
echo "walltime: `expr $TEND - $TBEGIN` seconds"


Note that 8 shared actually results in
 500-650 %CPU   6 ShMem   8 Linda. (Sometimes 7 ShMem)

%LindaWorkers=r27i1n9,r27i1n10,r27i2n2,r27i2n7,r27i2n10,r27i2n11,r27i3n0,r27i3n12
%NProcShared=8
%mem=16mw
 Job cpu time:  0 days  0 hours  0 minutes 36.0 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 10:33:48 2011.
real    2m49.695s
user    19m33.789s
sys     0m7.500s
put into t02
walltime: 169 

%LindaWorkers=r27i1n9,r27i1n10,r27i2n2,r27i2n7
%NProcShared=8
%mem=16mw
Job cpu time:  0 days  0 hours  0 minutes 18.4 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 10:40:58 2011.
real    3m49.377s
user    26m0.045s
sys     0m10.121s
put into t03
walltime: 229 seconds

%LindaWorkers=r27i1n9,r27i1n10,r27i2n2,r27i2n7
%NProcShared=8
%mem=16mw
Job cpu time:  0 days  0 hours  0 minutes 18.6 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 10:51:57 2011.
real    3m52.692s
user    26m26.743s
sys     0m9.829s
walltime: 232 seconds
did not save results
 
%LindaWorkers=r27i2n2,r27i2n7
%NProcShared=8
%mem=16mw
Job cpu time:  0 days  0 hours  0 minutes 27.7 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 10:59:27 2011.
real    6m12.719s
user    41m32.964s
sys     0m13.709s
walltime: 372 seconds
put into t04

[no LindaWorkers]
%NProcShared=8
%mem=16mw
 Job cpu time:  0 days  1 hours  9 minutes 15.7 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 11:13:23 2011.
real    10m31.822s
user    68m53.530s
sys     0m22.413s
walltime: 632 seconds
put into t05

[no LindaWorkers]
%NProcShared=4
%mem=16mw
Job cpu time:  0 days  1 hours  0 minutes 48.5 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 11:30:51 2011.
real    15m12.814s
user    60m32.023s
sys     0m16.669s
walltime: 913 seconds
did not save results
 
%LindaWorkers=r27i2n2,r27i2n7  not on node where executive launched.
%NProcShared=4
%mem=16mw
Job cpu time:  0 days  0 hours  0 minutes  8.7 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 11:41:16 2011.
real    8m34.641s
user    33m52.179s
sys     0m11.521s
walltime: 514 seconds

%LindaWorkers=r27i1n9,r27i1n10  linda workers include node where launched
%NProcShared=4
%mem=16mw
 Job cpu time:  0 days  0 hours  0 minutes  8.8 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 11:51:54 2011.
real    8m35.612s
user    33m52.583s
sys     0m15.021s
walltime: 515 seconds
did not save results

%LindaWorkers=r27i1n9,r27i1n10,r27i2n2,r27i2n7
%NProcShared=4
%mem=16mw
 Job cpu time:  0 days  0 hours  0 minutes  8.8 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 11:58:41 2011.
real    5m10.822s
user    20m13.332s
sys     0m8.533s
walltime: 311 seconds
did not save results

%LindaWorkers=r27i1n9,r27i1n10,r27i2n2,r27i2n7,r27i2n10,r27i2n11,r27i3n0,r27i3n12
%NProcShared=4
%mem=16mw
Job cpu time:  0 days  0 hours  0 minutes  8.8 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 12:04:21 2011.
real    3m29.522s
user    13m26.750s
sys     0m7.008s
walltime: 210 seconds
did not save results

%LindaWorkers=r27i1n9,r27i1n10,r27i2n2,r27i2n7,r27i2n10,r27i2n11,r27i3n0,r27i3n12
%NProcShared=2
%mem=16mw
 Job cpu time:  0 days  0 hours  0 minutes  4.3 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 12:11:14 2011.
real    5m35.881s
user    10m49.285s
sys     0m7.356s
walltime: 336 seconds
 
%LindaWorkers=r27i1n9,r27i1n10,r27i2n2,r27i2n7
%NProcShared=2
%mem=16mw
Job cpu time:  0 days  0 hours  0 minutes  4.2 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 12:21:49 2011
real    8m47.280s
user    17m12.953s
sys     0m8.953s
walltime: 527 seconds

%LindaWorkers=r27i1n9,r27i1n10
%NProcShared=2
%mem=16mw
 Job cpu time:  0 days  0 hours  0 minutes  4.2 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 12:38:17 2011.
real    15m9.658s
user    29m58.700s
sys     0m13.577s
walltime: 910 seconds

[no LindaWorkers]
%NProcShared=2
%mem=16mw
Job cpu time:  0 days  0 hours 55 minutes 29.1 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 13:07:05 2011.
real    27m45.100s
user    55m7.891s
sys     0m21.445s
walltime: 1665 seconds

[no LindaWorkers]
%NProcShared=1
%mem=16mw
Job cpu time:  0 days  0 hours 54 minutes  5.2 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 15:56:50 2011.
real    54m12.572s
user    53m28.549s
sys     0m36.842s
walltime: 3252 seconds

%LindaWorkers=r8i2n9,r8i2n11
%NProcShared=1
%mem=16mw
 Job cpu time:  0 days  0 hours  0 minutes  2.1 seconds.
File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 16:27:09 2011.
real    28m52.921s
user    28m44.980s
sys     0m4.752s
walltime: 1733 seconds

%LindaWorkers=r8i2n9,r8i2n11,r8i2n12,r8i3n4
%NProcShared=1
%mem=16mw
Job cpu time:  0 days  0 hours  0 minutes  2.1 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 16:48:08 2011.
real    16m8.724s
user    15m56.012s
sys     0m4.676s
walltime: 969 seconds


%LindaWorkers=r8i2n9,r8i2n11,r8i2n12,r8i3n4,r8i3n7,r8i3n12,r8i3n13,r9i0n4
%NProcShared=1
%mem=16mw
 Job cpu time:  0 days  0 hours  0 minutes  2.2 seconds.
 File lengths (MBytes):  RWF=    414 Int=      0 D2E=      0 Chk=     44 Scr=      1
 Normal termination of Gaussian 09 at Thu Mar  3 15:01:55 2011.
real    9m51.449s
user    9m32.692s
sys     0m4.924s
walltime: 592 seconds

        Gaussian g09.B01 on Diamond
        Executation time of test397.com (seconds)
                          number of nodes (LindaWorkers)
 number of processes      1      2      4      8
 on same node
 (NProcShared)
    1                  3252   1733    969    529
    2                  1665    910    527    336
    4                   913    515    311    210
    8                   632    372    231    169

 Notes.
 If times along the diagonal were constant, then a parallel process
 using Linda would be equivalent to a shared memory process.
 Generally a parallel process using Linda is slightly less
 effective than a shared-memory process.  The last row, showing
 8 shared memory processes per node, actually refers to 6 or 7
 processes per node.  The Gaussian program decides on how many
 shared memory processes to use for each computational step.  The
 choice is usually 6 and sometimes (rarely) 7 even though the
 parameter file specifies that 8 shared memory cores are available.
 As an estimate of how well Gaussian scales (for this particular
 test case) we see that with NProcShared=8, using 8 nodes gives
 a 3.7 times speedup

 --------------------------

        Gaussian g09.B01 on Garnet
        Executation time of test397.com (seconds)
                          number of nodes (LindaWorkers)
 number of processes      1      2      4      8
 on same node
 (NProcShared)
    1                  5247   2758   1552    962
    2                  2663   1459    858    554
    4                  1424    804    498    347
    8                   952    561    370    267
   16                   950    546    349    257


gaussian:x:753:duanx,,mshukla,scheinin,boatzj,crinders,dina,,rmassaro,radbalu,andreami,
scheinin@garnet03:..gaussian/work> 

gaussian
 aminga mbullock jeremyd alterb borchert scheinin
 duanx     Xiaofeng Duan
 mshukla   Manoj Shukla
 boatzj    Jerry Boatz
 crinders  Berend Rinderspacher      /bin/false
                                     berend.rinderspacher@us.army.mil
 dina      Dinadayalane Tandabany    /bin/false
 rmassaro  Richard Massaro
 radbalu   Radhakrishnan Balu
 andreami  Andrea Scott

Scott L. Anderson  anderson@chem.utah.edu

duanx.ctr@afrl.hpc.mil
Manoj.K.Shukla@usace.army.mil
jerry.boatz@edwards.af.mil
Ricky.D.Massaro@usace.army.mil
rad.balu@us.army.mil
andrea@icnanotox.org
berend.rinderspacher@us.army.mil
dina@icnanotox.org 


