<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML
><HEAD
><TITLE
>For the Impatient</TITLE
><META
NAME="GENERATOR"
CONTENT="Modular DocBook HTML Stylesheet Version 1.7"><LINK
REL="HOME"
TITLE="Intel® Trace Analyzer
     User's Reference Guide"
HREF="index.html"><LINK
REL="UP"
TITLE="Introduction"
HREF="c31.html"><LINK
REL="PREVIOUS"
TITLE="Online Resources"
HREF="x209.html"><LINK
REL="NEXT"
TITLE="The Main Menu"
HREF="c354.html"></HEAD
><BODY
CLASS="section"
BGCOLOR="#FFFFFF"
TEXT="#000000"
LINK="#0000FF"
VLINK="#840084"
ALINK="#0000FF"
><DIV
CLASS="NAVHEADER"
><TABLE
SUMMARY="Header navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TH
COLSPAN="3"
ALIGN="center"
>Intel® Trace Analyzer
     User's Reference Guide</TH
></TR
><TR
><TD
WIDTH="10%"
ALIGN="left"
VALIGN="bottom"
><A
HREF="x209.html"
ACCESSKEY="P"
>Prev</A
></TD
><TD
WIDTH="80%"
ALIGN="center"
VALIGN="bottom"
>Chapter 1. Introduction</TD
><TD
WIDTH="10%"
ALIGN="right"
VALIGN="bottom"
><A
HREF="c354.html"
ACCESSKEY="N"
>Next</A
></TD
></TR
></TABLE
><HR
ALIGN="LEFT"
WIDTH="100%"></DIV
><DIV
CLASS="section"
><H1
CLASS="section"
><A
NAME="IMPATIENT"
>1.5. For the Impatient</A
></H1
><P
>This section provides a quick start into the Intel
Trace Analyzer. It demonstrates essential features of the program
using the example trace files
<SAMP
CLASS="computeroutput"
>poisson_sendrecv.single.stf</SAMP
> and
<SAMP
CLASS="computeroutput"
>poisson_icomm.single.stf</SAMP
> that are
available in the Intel Trace Analyzer's examples directory.</P
><P
>The traces were generated with two implementations of the same
algorithm computing the same result over the same data set: a poisson
solver for a linear equation system. As the names imply, the first
version uses a sendrecv to communicate, while the second version uses
non-blocking communication.</P
><P
>It is illustrated that the first version leads to an overall
serialization of the parallel algorithm and how the improved version
solves the problem. <A
HREF="x217.html#FIG.QS.SR.LOADED"
>Figure 1-2</A
> shows the Intel
Trace Analyzer after loading
<SAMP
CLASS="computeroutput"
>poisson_sendrecv.single.stf</SAMP
>. The
figure shows a main window and a child window, a so called 
<SPAN
CLASS="emphasis"
><I
CLASS="emphasis"
>View</I
></SPAN
>. </P
><DIV
CLASS="figure"
><A
NAME="FIG.QS.SR.LOADED"
></A
><P
><B
>Figure 1-2. poisson_sendrecv.single.stf loaded</B
></P
><DIV
CLASS="mediaobject"
><P
><IMG
SRC="../graphics/qs_sr_loaded.png"
ALIGN="center"></P
></DIV
></DIV
><P
>Maximize the View with the respective button in its
title bar and open an Event Timeline (<SPAN
CLASS="guimenu"
>View Menu</SPAN
>-&gt;<SPAN
CLASS="guimenuitem"
>Charts</SPAN
>-&gt;<SPAN
CLASS="guimenuitem"
>Event Timeline</SPAN
>) as shown in <A
HREF="x217.html#FIG.QS.SR.OPEN.ETL"
>Figure 1-3</A
>. The result should look like in <A
HREF="x217.html#FIG.QS.SR.ETL.OPENED"
>Figure 1-4</A
>.
</P
><DIV
CLASS="figure"
><A
NAME="FIG.QS.SR.OPEN.ETL"
></A
><P
><B
>Figure 1-3. Opening an Event Timeline</B
></P
><DIV
CLASS="mediaobject"
><P
><IMG
SRC="../graphics/qs_sr_open_etl.png"
ALIGN="center"></P
></DIV
></DIV
><DIV
CLASS="figure"
><A
NAME="FIG.QS.SR.ETL.OPENED"
></A
><P
><B
>Figure 1-4. Event Timeline opened</B
></P
><DIV
CLASS="mediaobject"
><P
><IMG
SRC="../graphics/qs_sr_etl_opened.png"
ALIGN="center"></P
></DIV
></DIV
><P
>Together with the Event Timeline (see <A
HREF="c876.html#EVETIM"
>Section 4.1</A
>),
a time scale opens above the Timeline in the View. <A
HREF="x217.html#FIG.QS.SR.ETL.OPENED"
>Figure 1-4</A
> shows a View containing a time
scale, an Event Timeline and a Function Profile. These diagrams are
called Charts (see <A
HREF="c876.html"
>Chapter 4</A
>).
In the status bar (see <A
HREF="x767.html"
>Section 3.2</A
>) found at the bottom
of the View the current time interval and some other information are
shown.</P
><P
>Zoom into the interesting area on the right edge of the
Event Timeline by dragging the mouse over the desired time interval
with the left mouse button pressed as shown in <A
HREF="x217.html#FIG.QS.SR.ZOOMING"
>Figure 1-5</A
>. The result should look like in <A
HREF="x217.html#FIG.QS.SR.ZOOMED"
>Figure 1-6</A
>. Note the apparent iterative nature of
the application.</P
><DIV
CLASS="figure"
><A
NAME="FIG.QS.SR.ZOOMING"
></A
><P
><B
>Figure 1-5. Zooming into a Chart</B
></P
><DIV
CLASS="mediaobject"
><P
><IMG
SRC="../graphics/qs_sr_zooming.png"
ALIGN="center"></P
></DIV
></DIV
><DIV
CLASS="figure"
><A
NAME="FIG.QS.SR.ZOOMED"
></A
><P
><B
>Figure 1-6. Zoomed result</B
></P
><DIV
CLASS="mediaobject"
><P
><IMG
SRC="../graphics/qs_sr_zoomed.png"
ALIGN="center"></P
></DIV
></DIV
><P
>Now zoom further into the trace to look at a single iteration and close the Function Profile (<SPAN
CLASS="guimenu"
>Context Menu</SPAN
>-&gt;<SPAN
CLASS="guimenuitem"
>Close Chart</SPAN
>). The result should look like
<A
HREF="x217.html#FIG.QS.SR.ONE.ITERATION"
>Figure 1-7</A
>.</P
><DIV
CLASS="figure"
><A
NAME="FIG.QS.SR.ONE.ITERATION"
></A
><P
><B
>Figure 1-7. Zoomed to one iteration</B
></P
><DIV
CLASS="mediaobject"
><P
><IMG
SRC="../graphics/qs_sr_one_iteration.png"
ALIGN="center"></P
></DIV
></DIV
><P
>To see which particular MPI functions are used in the program, right-click on MPI in the Event Timeline and choose <SPAN
CLASS="emphasis"
><I
CLASS="emphasis"
>Ungroup Group MPI</I
></SPAN
>. The result should look like <A
HREF="x217.html#FIG.QS.SR.MPI.UNGROUPED"
>Figure 1-8</A
>. The Function Aggregation of the View changes so that the MPI functions are no longer aggregated (see <A
HREF="x3028.html"
>Section 10.2</A
>) into the Function Group MPI but are shown individually. This is shown in the status bar. The button titled <SPAN
CLASS="emphasis"
><I
CLASS="emphasis"
>Major Function Groups</I
></SPAN
> changes to <SPAN
CLASS="emphasis"
><I
CLASS="emphasis"
>MPI expanded in (Major Function Groups)</I
></SPAN
>. Click this button to open the <SPAN
CLASS="emphasis"
><I
CLASS="emphasis"
>Function Group Editor</I
></SPAN
> (see <A
HREF="x2307.html"
>Section 5.4</A
>), which enables you to create new function groups and to switch between them.</P
><DIV
CLASS="figure"
><A
NAME="FIG.QS.SR.MPI.UNGROUPED"
></A
><P
><B
>Figure 1-8. MPI ungrouped </B
></P
><DIV
CLASS="mediaobject"
><P
><IMG
SRC="../graphics/qs_sr_mpi_ungrouped.png"
ALIGN="center"></P
></DIV
></DIV
><P
>It is apparent that at the start of the iteration the processes communicate with their direct neighbors using <SAMP
CLASS="computeroutput"
>MPI_Sendrecv</SAMP
>. The way this data exchange is implemented shows a clear disadvantage: process <SPAN
CLASS="emphasis"
><I
CLASS="emphasis"
>i</I
></SPAN
> does not exchange data with its neighbor
<SPAN
CLASS="emphasis"
><I
CLASS="emphasis"
>i+1</I
></SPAN
> until the exchange between <SPAN
CLASS="emphasis"
><I
CLASS="emphasis"
>i-1</I
></SPAN
> and <SPAN
CLASS="emphasis"
><I
CLASS="emphasis"
>i</I
></SPAN
> is
complete. This makes the first
<SAMP
CLASS="computeroutput"
>MPI_Sendrecv</SAMP
> block look like a
staircase.  The second block is already deferred and hence does not
show the same effect.  The
<SAMP
CLASS="computeroutput"
>MPI_Allreduce</SAMP
> at the end of the
iteration nearly resynchronizes all processes. The net effect is that
the processes spend most of their time waiting for each other.</P
><P
>Looking at the status bar (see <A
HREF="x217.html#FIG.QS.SR.MPI.UNGROUPED"
>Figure 1-8</A
>) shows that one iteration is
roughly 1.5 milliseconds long.</P
><P
><A
HREF="x217.html#FIG.QS.SR.MANY.CHARTS"
>Figure 1-9</A
> shows a View with an
Event Timeline (<SPAN
CLASS="guimenu"
>View Menu</SPAN
>-&gt;<SPAN
CLASS="guimenuitem"
>Charts</SPAN
>-&gt;<SPAN
CLASS="guimenuitem"
>Event Timeline</SPAN
>), two Function Profiles (<SPAN
CLASS="guimenu"
>View Menu</SPAN
>-&gt;<SPAN
CLASS="guimenuitem"
>Charts</SPAN
>-&gt;<SPAN
CLASS="guimenuitem"
>Function Profile</SPAN
>) with their Load Balance tab and
a Message profile (<SPAN
CLASS="guimenu"
>View Menu</SPAN
>-&gt;<SPAN
CLASS="guimenuitem"
>Charts</SPAN
>-&gt;<SPAN
CLASS="guimenuitem"
>Message Profile</SPAN
>) that reveals the asymmetric pattern in the point to point messages.</P
><P
>Note that the time spent in
<SAMP
CLASS="computeroutput"
>MPI_Sendrecv</SAMP
> grows with the process
number while the time for
<SAMP
CLASS="computeroutput"
>MPI_Allreduce</SAMP
> decreases. The Message Profile (<A
HREF="x1569.html"
>Section 4.6</A
>) in the bottom right corner of <A
HREF="x217.html#FIG.QS.SR.MANY.CHARTS"
>Figure 1-9</A
> shows that messages traveling
from a higher rank to a lower rank need more and more time with increasing
rank while the messages traveling from lower rank to higher rank do
reveal a weak even-odd kind of pattern.</P
><DIV
CLASS="figure"
><A
NAME="FIG.QS.SR.MANY.CHARTS"
></A
><P
><B
>Figure 1-9. Many Charts</B
></P
><DIV
CLASS="mediaobject"
><P
><IMG
SRC="../graphics/qs_sr_many_charts.png"
ALIGN="center"></P
></DIV
></DIV
><P
>As <SAMP
CLASS="computeroutput"
>poisson_sendrecv.single.stf</SAMP
>
is such a striking example of serialization, next to all Charts
provided by the Intel Trace Analyzer reveal this interesting
pattern. But in real world cases it might be necessary to formulate a
hypothesis regarding how the program should behave and to check this
hypothesis using the most adequate Chart.</P
><P
>A possible way to improve the performance of the program is to
use non-blocking communication to replace the usage of
<SAMP
CLASS="computeroutput"
>MPI_Sendrecv</SAMP
> and to avoid the
serialization in this way. One iteration of the resulting program
looks like the one shown in <A
HREF="x217.html#FIG.QS.IC.ONE.ITERATION"
>Figure 1-10</A
>. Note that a single iteration now
takes about 0.9 milliseconds, while it took about 1.4 milliseconds
before the change.</P
><DIV
CLASS="figure"
><A
NAME="FIG.QS.IC.ONE.ITERATION"
></A
><P
><B
>Figure 1-10. One iteration of the improved version</B
></P
><DIV
CLASS="mediaobject"
><P
><IMG
SRC="../graphics/qs_ic_one_iteration.png"
ALIGN="center"></P
></DIV
></DIV
><P
>To compare two trace files the Intel Trace Analyzer offers the so
called Comparison View (see <A
HREF="c2725.html"
>Chapter 7</A
>). Just
use the menu entry
<SPAN
CLASS="guimenu"
>View Menu</SPAN
>-&gt;<SPAN
CLASS="guimenuitem"
>View</SPAN
>-&gt;<SPAN
CLASS="guimenuitem"
>Compare</SPAN
>
in the View showing <SAMP
CLASS="computeroutput"
>poisson_sendrecv.single.stf</SAMP
>. In the now appearing dialog choose another View that shows
<SAMP
CLASS="computeroutput"
>poisson_icomm.single.stf</SAMP
>. A new
Comparison View is opened that shows an Event Timeline for each file
and a Comparison Function Profile Chart (see <A
HREF="x2820.html#COMP.FUNC"
>Section 7.2.1</A
>) that
shows a profile computed from both tracefiles. The time intervals,
aggregation settings and filters are taken from the original Views.</P
><P
>After adjusting some configurable behavior (see <A
HREF="c2725.html"
>Chapter 7</A
>) and zooming to the first iteration in
each trace file a Comparison View for these two files can look like
in <A
HREF="x217.html#COMP.ONEITER"
>Figure 1-11</A
>. Now it is immediately obvious that
one iteration in the improved program needs considerable less time
than in the original program.</P
><DIV
CLASS="figure"
><A
NAME="COMP.ONEITER"
></A
><P
><B
>Figure 1-11. Comparing the first iterations taken from two program runs</B
></P
><DIV
CLASS="mediaobject"
><P
><IMG
SRC="../graphics/comp_poisson_one_iter.png"
ALIGN="center"></P
></DIV
></DIV
><P
>Please note that you can create a Comparison View that compares
one time interval and one process group against another time interval
and another process group of the same trace file. Other useful
applications of the Comparison View include scalability analysis where
you compare two runs of the same unmodified program with different
processor counts and try to find out which functions scale well and
which suffer from Amdahls Law. Other scenarios could be the
comparison of two different MPI libraries, interconnects or
machines.</P
><P
>Of course this introduction only scratches the surface. If there
is not enough time to browse through the whole documentation, it is
recommended to at least read through <A
HREF="c3010.html"
>Chapter 10</A
>
to learn about features like filtering, tagging, process aggregation
and function aggregation. These features have the potential to make
analyzing parallel applications more efficient.</P
></DIV
><DIV
CLASS="NAVFOOTER"
><HR
ALIGN="LEFT"
WIDTH="100%"><TABLE
SUMMARY="Footer navigation table"
WIDTH="100%"
BORDER="0"
CELLPADDING="0"
CELLSPACING="0"
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
><A
HREF="x209.html"
ACCESSKEY="P"
>Prev</A
></TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="index.html"
ACCESSKEY="H"
>Home</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
><A
HREF="c354.html"
ACCESSKEY="N"
>Next</A
></TD
></TR
><TR
><TD
WIDTH="33%"
ALIGN="left"
VALIGN="top"
>Online Resources</TD
><TD
WIDTH="34%"
ALIGN="center"
VALIGN="top"
><A
HREF="c31.html"
ACCESSKEY="U"
>Up</A
></TD
><TD
WIDTH="33%"
ALIGN="right"
VALIGN="top"
>The Main Menu</TD
></TR
></TABLE
></DIV
></BODY
></HTML
>